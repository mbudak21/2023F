{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.linalg as linalg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"hw02_data_points.csv\", delimiter = \",\") / 255\n",
    "y = np.genfromtxt(\"hw02_class_labels.csv\", delimiter = \",\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = np.hstack((np.reshape(X[np.where(y == 1)[0][0:5], :], (28 * 5, 28)),\n",
    "                np.reshape(X[np.where(y == 2)[0][0:5], :], (28 * 5, 28)),\n",
    "                np.reshape(X[np.where(y == 3)[0][0:5], :], (28 * 5, 28)),\n",
    "                np.reshape(X[np.where(y == 4)[0][0:5], :], (28 * 5, 28)),\n",
    "                np.reshape(X[np.where(y == 5)[0][0:5], :], (28 * 5, 28)),\n",
    "                np.reshape(X[np.where(y == 6)[0][0:5], :], (28 * 5, 28)),\n",
    "                np.reshape(X[np.where(y == 7)[0][0:5], :], (28 * 5, 28)),\n",
    "                np.reshape(X[np.where(y == 8)[0][0:5], :], (28 * 5, 28)),\n",
    "                np.reshape(X[np.where(y == 9)[0][0:5], :], (28 * 5, 28)),\n",
    "                np.reshape(X[np.where(y == 10)[0][0:5], :], (28 * 5, 28))))\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(i1, cmap = \"gray\")\n",
    "plt.show()\n",
    "fig.savefig(\"hw02_images.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# STEP 3\n",
    "# first 60000 data points should be included to train\n",
    "# remaining 10000 data points should be included to test\n",
    "# should return X_train, y_train, X_test, and y_test\n",
    "def train_test_split(X, y):\n",
    "    # your implementation starts below\n",
    "    trainset_size = 60000\n",
    "\n",
    "    X_train = X[0:trainset_size]\n",
    "    X_test = X[trainset_size:]\n",
    "\n",
    "    y_train = y[0:trainset_size]\n",
    "    y_test = y[trainset_size:]\n",
    "    # your implementation ends above\n",
    "    return(X_train, y_train, X_test, y_test)\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4\n",
    "# assuming that there are N data points and K classes\n",
    "# should return a numpy array with shape (N, K)\n",
    "def sigmoid(X, W, w0):\n",
    "    # your implementation starts below\n",
    "\n",
    "    Z = np.dot(X, W) + w0\n",
    "    scores = 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    # your implementation ends above\n",
    "    return(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5\n",
    "# assuming that there are N data points and K classes\n",
    "# should return a numpy array with shape (N, K)\n",
    "def one_hot_encoding(y):\n",
    "    # your implementation starts below\n",
    "    \n",
    "    K = np.max(y)\n",
    "    Y = np.zeros((y.shape[0], K))\n",
    "    Y[np.arange(y.shape[0]), y-1] = 1\n",
    "    \n",
    "\n",
    "    # your implementation ends above\n",
    "    return(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(421)\n",
    "D = X_train.shape[1]\n",
    "K = np.max(y_train)\n",
    "Y_train = one_hot_encoding(y_train)\n",
    "W_initial = np.random.uniform(low = -0.001, high = 0.001, size = (D, K))\n",
    "w0_initial = np.random.uniform(low = -0.001, high = 0.001, size = (1, K))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_W(X, Y_truth, Y_predicted):\n",
    "    # Calculate the gradient for W\n",
    "    gradient = np.dot(X.T, (Y_predicted - Y_truth))\n",
    "    return gradient\n",
    "\n",
    "def gradient_w0(Y_truth, Y_predicted):\n",
    "    # Calculate the gradient for w0\n",
    "    gradient = np.sum(Y_predicted - Y_truth, axis=0, keepdims=True)\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrimination_by_regression(X_train, Y_train, W_initial, w0_initial):\n",
    "    eta = 0.15 / X_train.shape[0]\n",
    "    iteration_count = 250\n",
    "    objective_values = np.zeros(iteration_count)\n",
    "\n",
    "    W = W_initial\n",
    "    w0 = w0_initial\n",
    "\n",
    "    for i in range(iteration_count):\n",
    "        Y_predicted = sigmoid(X_train, W, w0)\n",
    "        W -= eta * gradient_W(X_train, Y_train, Y_predicted)\n",
    "        w0 -= eta * gradient_w0(Y_train, Y_predicted)\n",
    "        objective_values[i] = np.mean(np.square(Y_train - Y_predicted))\n",
    "\n",
    "    return W, w0, objective_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02722328 -0.04347337 -0.02111757 ... -0.07433908  0.03117338\n",
      "  -0.03034875]\n",
      " [-0.0281615  -0.04363394 -0.01952827 ... -0.0746548   0.03061923\n",
      "  -0.02878167]\n",
      " [-0.02869553 -0.04405139 -0.01988933 ... -0.07542943  0.03035676\n",
      "  -0.02915221]\n",
      " ...\n",
      " [-0.01314161 -0.0399353  -0.04685416 ... -0.0652039   0.03186524\n",
      "  -0.02886239]\n",
      " [-0.02346936 -0.04185863 -0.02501464 ... -0.07078822  0.03052673\n",
      "  -0.02941791]\n",
      " [-0.02702793 -0.04446439 -0.0201028  ... -0.07504715  0.03166832\n",
      "  -0.03027302]]\n",
      "[[-0.02842322 -0.04365182 -0.02042847 -0.06506608 -0.03701367 -0.13544601\n",
      "  -0.05479702 -0.07387561  0.03213723 -0.02884389]]\n",
      "[0.24913447 0.1        0.09999996 0.0999936  0.0911144  0.15981149\n",
      " 0.13472274 0.1082801  0.10474261 0.08887361]\n"
     ]
    }
   ],
   "source": [
    "W, w0, objective_values = discrimination_by_regression(X_train, Y_train,\n",
    "                                                       W_initial, w0_initial)\n",
    "print(W)\n",
    "print(w0)\n",
    "print(objective_values[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
