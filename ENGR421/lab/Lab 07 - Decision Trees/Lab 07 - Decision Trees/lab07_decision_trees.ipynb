{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 07 - Decision Trees\n",
    "## Mehmet Gönen\n",
    "### December 1, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def safelog2(x):\n",
    "    if x == 0:\n",
    "        return(0)\n",
    "    else:\n",
    "        return(np.log2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into memory\n",
    "data_set = np.genfromtxt(\"lab07_data_set.csv\", delimiter = \",\")\n",
    "\n",
    "# get number of samples and number of features\n",
    "N = data_set.shape[0]\n",
    "D = data_set.shape[1] - 1\n",
    "\n",
    "# get X and y values\n",
    "X = data_set[:, 0:D]\n",
    "y = data_set[:, D:(D + 1)].astype(int)\n",
    "\n",
    "# get number of classes\n",
    "K = np.max(y)\n",
    "\n",
    "# get train and test splits\n",
    "train_indices = np.concatenate((np.arange(0, 25),\n",
    "                                np.arange(50, 75),\n",
    "                                np.arange(100, 125)))\n",
    "test_indices = np.setdiff1d(range(N), train_indices)\n",
    "\n",
    "X_train = X[train_indices,:]\n",
    "y_train = y[train_indices]\n",
    "X_test = X[test_indices,:]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "# get numbers of train and test samples\n",
    "N_train = len(y_train)\n",
    "N_test = len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create necessary data structures\n",
    "node_indices = {}\n",
    "is_terminal = {}\n",
    "need_split = {}\n",
    "\n",
    "node_features = {}\n",
    "node_splits = {}\n",
    "node_frequencies = {}\n",
    "\n",
    "# put all training instances into the root node\n",
    "node_indices[1] = np.array(range(N_train)) # Put all training instances into the root node\n",
    "is_terminal[1] = False\n",
    "need_split[1] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| [key for key, value in need_split.items()\n",
      "    if value == True]: [1]\n",
      "ic| [np.sum(y_train[data_indices] == (c + 1))\n",
      "    for c in range(K)]: [25, 25, 25]\n",
      "ic| [key for key, value in need_split.items()\n",
      "    if value == True]: [2, 3]\n",
      "ic| [np.sum(y_train[data_indices] == (c + 1))\n",
      "    for c in range(K)]: [0, 25, 25]\n",
      "ic| [np.sum(y_train[data_indices] == (c + 1))\n",
      "    for c in range(K)]: [25, 0, 0]\n",
      "ic| [key for key, value in need_split.items()\n",
      "    if value == True]: [4, 5]\n",
      "ic| [np.sum(y_train[data_indices] == (c + 1))\n",
      "    for c in range(K)]: [0, 1, 24]\n",
      "ic| [np.sum(y_train[data_indices] == (c + 1))\n",
      "    for c in range(K)]: [0, 24, 1]\n",
      "ic| [key for key, value in need_split.items()\n",
      "    if value == True]: [8, 9, 10, 11]\n",
      "ic| [np.sum(y_train[data_indices] == (c + 1))\n",
      "    for c in range(K)]: [0, 0, 23]\n",
      "ic| [np.sum(y_train[data_indices] == (c + 1))\n",
      "    for c in range(K)]: [0, 1, 1]\n",
      "ic| [np.sum(y_train[data_indices] == (c + 1))\n",
      "    for c in range(K)]: [0, 0, 1]\n",
      "ic| [np.sum(y_train[data_indices] == (c + 1))\n",
      "    for c in range(K)]: [0, 24, 0]\n",
      "ic| [key for key, value in need_split.items()\n",
      "    if value == True]: [18, 19]\n",
      "ic| [np.sum(y_train[data_indices] == (c + 1))\n",
      "    for c in range(K)]: [0, 1, 0]\n",
      "ic| [np.sum(y_train[data_indices] == (c + 1))\n",
      "    for c in range(K)]: [0, 0, 1]\n",
      "ic| [key for key, value in need_split.items()\n",
      "    if value == True]: []\n"
     ]
    }
   ],
   "source": [
    "from icecream import ic\n",
    "# learning algorithm\n",
    "while True:\n",
    "    # find nodes that need splitting\n",
    "    split_nodes = [key for key, value in need_split.items()\n",
    "                   if value == True]\n",
    "    # check whether we reach all terminal nodes\n",
    "    if len(split_nodes) == 0:\n",
    "        break\n",
    "    # find best split positions for all nodes\n",
    "    for split_node in split_nodes:\n",
    "        data_indices = node_indices[split_node] # get data indices for the node\n",
    "        need_split[split_node] = False\n",
    "        node_frequencies[split_node] = [np.sum(y_train[data_indices] == (c + 1))\n",
    "                                        for c in range(K)] # get class frequencies\n",
    "        if len(np.unique(y_train[data_indices])) == 1: # check whether all instances in the node belong to the same class\n",
    "            is_terminal[split_node] = True # We have reached a pure node\n",
    "        else:\n",
    "            is_terminal[split_node] = False # We have not reached a pure node\n",
    "\n",
    "            # find best split position for the node\n",
    "            best_scores = np.repeat(0.0, D) # initialize best scores\n",
    "            best_splits = np.repeat(0.0, D) # initialize best splits\n",
    "            for d in range(D): # for all features\n",
    "                unique_values = np.sort(np.unique(X_train[data_indices, d])) # get unique values of the feature\n",
    "                split_positions = (unique_values[1:] + unique_values[:-1]) / 2 # get split positions\n",
    "                split_scores = np.repeat(0.0, len(split_positions))\n",
    "                for s in range(len(split_positions)): # for each split position\n",
    "                    # Calculate the score for the split\n",
    "\n",
    "                    left_indices = data_indices[X_train[data_indices, d] > \\\n",
    "                                   split_positions[s]]\n",
    "                    right_indices = data_indices[X_train[data_indices, d] <= \\\n",
    "                                    split_positions[s]]\n",
    "                    split_scores[s] = -(len(left_indices) / len(data_indices) * \\\n",
    "                                        np.sum([np.mean(y_train[left_indices] == (c + 1)) * \\\n",
    "                                                safelog2(np.mean(y_train[left_indices] == (c + 1)))\n",
    "                                                for c in range(K)]) + \\\n",
    "                                        len(right_indices) / len(data_indices) * \\\n",
    "                                        np.sum([np.mean(y_train[right_indices] == (c + 1)) * \\\n",
    "                                                safelog2(np.mean(y_train[right_indices] == (c + 1)))\n",
    "                                                for c in range(K)]))\n",
    "                best_scores[d] = np.min(split_scores)\n",
    "                best_splits[d] = split_positions[np.argmin(split_scores)]\n",
    "            # decide where to split on which feature\n",
    "            split_d = np.argmin(best_scores)\n",
    "\n",
    "            node_features[split_node] = split_d\n",
    "            node_splits[split_node] = best_splits[split_d]\n",
    "            \n",
    "            # create left node using the selected split\n",
    "            left_indices = data_indices[X_train[data_indices, split_d] > \\\n",
    "                           best_splits[split_d]]\n",
    "            node_indices[2 * split_node] = left_indices\n",
    "            is_terminal[2 * split_node] = False\n",
    "            need_split[2 * split_node] = True\n",
    "      \n",
    "            # create right node using the selected split\n",
    "            right_indices = data_indices[X_train[data_indices, split_d] <= \\\n",
    "                            best_splits[split_d]]\n",
    "            node_indices[2 * split_node + 1] = right_indices\n",
    "            is_terminal[2 * split_node + 1] = False\n",
    "            need_split[2 * split_node + 1] = True\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 03: ['x3 <= 2.60'] => [25, 0, 0]\n",
      "Node 08: ['x3 > 2.60' 'x4 > 1.65' 'x3 > 4.85'] => [0, 0, 23]\n",
      "Node 10: ['x3 > 2.60' 'x4 <= 1.65' 'x3 > 4.95'] => [0, 0, 1]\n",
      "Node 11: ['x3 > 2.60' 'x4 <= 1.65' 'x3 <= 4.95'] => [0, 24, 0]\n",
      "Node 18: ['x3 > 2.60' 'x4 > 1.65' 'x3 <= 4.85' 'x1 > 5.40'] => [0, 1, 0]\n",
      "Node 19: ['x3 > 2.60' 'x4 > 1.65' 'x3 <= 4.85' 'x1 <= 5.40'] => [0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# extract rules\n",
    "terminal_nodes = [key for key, value in is_terminal.items()\n",
    "                  if value == True]\n",
    "for terminal_node in terminal_nodes:\n",
    "    index = terminal_node\n",
    "    rules = np.array([])\n",
    "    while index > 1:\n",
    "        parent = np.floor(index / 2)\n",
    "        if index % 2 == 0:\n",
    "            # if node is left child of its parent\n",
    "            rules = np.append(rules, \n",
    "                              \"x{:d} > {:.2f}\".format(node_features[parent] + 1,\n",
    "                                                      node_splits[parent]))\n",
    "        else:\n",
    "            # if node is right child of its parent\n",
    "            rules = np.append(rules,\n",
    "                              \"x{:d} <= {:.2f}\".format(node_features[parent] + 1,\n",
    "                                                       node_splits[parent]))\n",
    "        index = parent\n",
    "    rules = np.flip(rules)\n",
    "    print(\"Node {:02}: {} => {}\".format(terminal_node, rules, node_frequencies[terminal_node]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train       1   2   3\n",
      "y_predicted            \n",
      "1            25   0   0\n",
      "2             0  25   0\n",
      "3             0   0  25\n"
     ]
    }
   ],
   "source": [
    "# traverse tree for training data points\n",
    "y_predicted = np.repeat(0, N_train)\n",
    "for i in range(N_train):\n",
    "    index = 1\n",
    "    while True:\n",
    "        if is_terminal[index] == True:\n",
    "            y_predicted[i] = np.argmax(node_frequencies[index]) + 1\n",
    "            break\n",
    "        else:\n",
    "            if X_train[i, node_features[index]] > node_splits[index]:\n",
    "                index = 2 * index\n",
    "            else:\n",
    "                index = 2 * index + 1\n",
    "confusion_matrix = pd.crosstab(y_predicted, y_train.T,\n",
    "                               rownames = [\"y_predicted\"],\n",
    "                               colnames = [\"y_train\"])\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test        1   2   3\n",
      "y_predicted            \n",
      "1            25   0   0\n",
      "2             0  23   2\n",
      "3             0   2  23\n"
     ]
    }
   ],
   "source": [
    "# traverse tree for test data points\n",
    "y_predicted = np.repeat(0, N_test)\n",
    "for i in range(N_test):\n",
    "    index = 1\n",
    "    while True:\n",
    "        if is_terminal[index] == True:\n",
    "            y_predicted[i] = np.argmax(node_frequencies[index]) + 1\n",
    "            break\n",
    "        else:\n",
    "            if X_test[i, node_features[index]] > node_splits[index]:\n",
    "                index = 2 * index\n",
    "            else:\n",
    "                index = 2 * index + 1\n",
    "confusion_matrix = pd.crosstab(y_predicted, y_test.T,\n",
    "                               rownames = [\"y_predicted\"],\n",
    "                               colnames = [\"y_test\"])\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
