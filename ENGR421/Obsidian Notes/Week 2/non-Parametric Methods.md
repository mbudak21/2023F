
Non-parametric methods in machine learning are techniques that do not make strong assumptions about the form of the mapping function from input variables to output variables. These methods are flexible and useful for analysis when the shape of the distribution is unknown.

Related: [[Parametric Methods]]
Examples: [[non-parametric Regression]] [[Kernel Methods]], [[Decision Trees]], K-Nearest Neighbors ([[KNN]])
## Flexibility
Non-parametric methods are favored for their flexibility as they do not require a pre-specified model form. This allows them to adapt to the shape of the data, accommodating more complexity than many parametric models.
## Advantages
Non-parametric methods are powerful when dealing with classification and regression problems where the relationships between variables are not well defined or are highly complex.
## Challenges
These methods often need more data to be accurate and can be computationally demanding. They are also more prone to issues like overfitting and can be affected by the curse of dimensionality in high-dimensional space.
## Applications
Widely applied in image processing, pattern recognition, and other fields where data distributions are complex or unknown, non-parametric methods are an essential tool in the machine learning toolbox.


[[non-parametric Density Estimation]]
