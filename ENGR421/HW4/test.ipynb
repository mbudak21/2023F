{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into memory\n",
    "data_set_train = np.genfromtxt(\"hw04_data_set_train.csv\", delimiter = \",\", skip_header = 1)\n",
    "data_set_test = np.genfromtxt(\"hw04_data_set_test.csv\", delimiter = \",\", skip_header = 1)\n",
    "\n",
    "# get x and y values\n",
    "X_train = data_set_train[:, 0:1]\n",
    "y_train = data_set_train[:, 1]\n",
    "X_test = data_set_test[:, 0:1]\n",
    "y_test = data_set_test[:, 1]\n",
    "\n",
    "# set drawing parameters\n",
    "minimum_value = 1.5\n",
    "maximum_value = 5.1\n",
    "step_size = 0.001\n",
    "X_interval = np.arange(start = minimum_value, stop = maximum_value + step_size, step = step_size)\n",
    "X_interval = X_interval.reshape(len(X_interval), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure(X_train, y_train, X_test, y_test, X_interval, y_interval_hat):\n",
    "    fig = plt.figure(figsize = (8, 4))\n",
    "    plt.plot(X_train[:, 0], y_train, \"b.\", markersize = 10)\n",
    "    plt.plot(X_test[:, 0], y_test, \"r.\", markersize = 10)\n",
    "    plt.plot(X_interval[:, 0], y_interval_hat, \"k-\")\n",
    "    plt.xlabel(\"Eruption time (min)\")\n",
    "    plt.ylabel(\"Waiting time to next eruption (min)\")\n",
    "    plt.legend([\"training\", \"test\"])\n",
    "    plt.show()\n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2\n",
    "# should return necessary data structures for trained tree\n",
    "def decision_tree_regression_train(X_train, y_train, P):\n",
    "    # create necessary data structures\n",
    "    node_indices = {}\n",
    "    is_terminal = {}\n",
    "    need_split = {}\n",
    "\n",
    "\n",
    "    node_features = {}\n",
    "    node_splits = {}\n",
    "    node_means = {} # Instead of frequencies, we store the mean of y values in each node\n",
    "    # your implementation starts below\n",
    "\n",
    "    # Initialization\n",
    "    node_indices = {0: np.arange(X_train.shape[0])}\n",
    "    is_terminal = {0: False}\n",
    "    need_split = {0: True}\n",
    "\n",
    "    while True:\n",
    "        split_nodes = [node for node, need in need_split.items() if need]\n",
    "        if not split_nodes:\n",
    "            break\n",
    "\n",
    "        for node in split_nodes:\n",
    "            data_indices = node_indices[node]\n",
    "            if len(data_indices) <= P:\n",
    "                is_terminal[node] = True\n",
    "                need_split[node] = False\n",
    "                node_means[node] = np.mean(y_train[data_indices]) if data_indices.size > 0 else 0\n",
    "                continue\n",
    "\n",
    "            best_feature, best_split, min_mse = None, None, float(\"inf\")\n",
    "            for feature in range(X_train.shape[1]):\n",
    "                unique_splits = np.unique(X_train[data_indices, feature])\n",
    "                for split in unique_splits:\n",
    "                    left_indices = data_indices[X_train[data_indices, feature] < split]\n",
    "                    right_indices = data_indices[X_train[data_indices, feature] >= split]\n",
    "                    \n",
    "                    # Only attempt to split if both left and right have more than zero elements\n",
    "                    if len(left_indices) > 0 and len(right_indices) > 0:\n",
    "                        left_mean = np.mean(y_train[left_indices])\n",
    "                        right_mean = np.mean(y_train[right_indices])\n",
    "                        \n",
    "                        left_mse = np.mean((y_train[left_indices] - left_mean) ** 2)\n",
    "                        right_mse = np.mean((y_train[right_indices] - right_mean) ** 2)\n",
    "                        \n",
    "                        mse = (len(left_indices) * left_mse + len(right_indices) * right_mse) / len(data_indices)\n",
    "                        \n",
    "                        if mse < min_mse:\n",
    "                            min_mse = mse\n",
    "                            best_feature = feature\n",
    "                            best_split = split\n",
    "                unique_splits = np.unique(X_train[data_indices, feature])\n",
    "                for split in unique_splits:\n",
    "                    left_indices = data_indices[X_train[data_indices, feature] < split]\n",
    "                    right_indices = data_indices[X_train[data_indices, feature] >= split]\n",
    "\n",
    "\n",
    "            if best_feature is not None:\n",
    "                left_indices = data_indices[X_train[data_indices, best_feature] < best_split]\n",
    "                right_indices = data_indices[X_train[data_indices, best_feature] >= best_split]\n",
    "\n",
    "                left_node = len(node_indices)\n",
    "                right_node = left_node + 1\n",
    "\n",
    "                node_indices[left_node] = left_indices\n",
    "                node_indices[right_node] = right_indices\n",
    "                is_terminal[node] = False\n",
    "                need_split[node] = False\n",
    "                is_terminal[left_node] = False\n",
    "                need_split[left_node] = True\n",
    "                is_terminal[right_node] = False\n",
    "                need_split[right_node] = True\n",
    "                node_features[node] = best_feature\n",
    "                node_splits[node] = best_split\n",
    "                node_means[node] = np.mean(y_train[data_indices])\n",
    "\n",
    "            else:\n",
    "                is_terminal[node] = True\n",
    "                need_split[node] = False\n",
    "                node_means[node] = np.mean(y_train[data_indices]) if data_indices.size > 0 else 0\n",
    "\n",
    "    # your implementation ends above\n",
    "    return(is_terminal, node_features, node_splits, node_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 70.73333333333333,\n",
       " 1: 54.75,\n",
       " 2: 80.25531914893617,\n",
       " 3: 53.86363636363637,\n",
       " 4: 58.0,\n",
       " 5: 76.92105263157895,\n",
       " 6: 82.51785714285714,\n",
       " 7: 58.333333333333336,\n",
       " 8: 53.53658536585366,\n",
       " 9: 73.0,\n",
       " 10: 77.38235294117646,\n",
       " 11: 82.27272727272727,\n",
       " 12: 96.0,\n",
       " 13: 52.57692307692308,\n",
       " 14: 55.2,\n",
       " 15: 81.5,\n",
       " 16: 76.5,\n",
       " 17: 84.5,\n",
       " 18: 81.77777777777777,\n",
       " 19: 54.1764705882353,\n",
       " 20: 49.55555555555556,\n",
       " 21: 74.0,\n",
       " 22: 77.18181818181819,\n",
       " 23: 80.1875,\n",
       " 24: 82.65517241379311,\n",
       " 25: 82.89285714285714,\n",
       " 26: 76.0,\n",
       " 27: 82.13636363636364,\n",
       " 28: 85.66666666666667}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_regression_train(X_train, y_train, 25)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_get_y_hat(x, is_terminal, node_features, node_splits, node_means):\n",
    "    node = 0\n",
    "    while not is_terminal[node]:  # Continue until a terminal node is reached\n",
    "\n",
    "        split = node_splits[node]\n",
    "\n",
    "        if x < split:\n",
    "            node = 2 * node + 1  # Go to left child\n",
    "        else:\n",
    "            node = 2 * node + 2  # Go to right child\n",
    "\n",
    "    return node_means[node]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3\n",
    "# assuming that there are N query data points\n",
    "# should return a numpy array with shape (N,)\n",
    "def decision_tree_regression_test(X_query, is_terminal, node_features, node_splits, node_means):\n",
    "    # your implementation starts below\n",
    "    y_hat = np.zeros(X_query.shape[0])\n",
    "    for i, x in enumerate(X_query):\n",
    "        y_hat[i] = decision_tree_get_y_hat(x, is_terminal, node_features, node_splits, node_means)\n",
    "    # your implementation ends above\n",
    "    return(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58.33333333, 96.        , 55.2       ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_terminal, node_features, node_splits, node_means = decision_tree_regression_train(X_train, y_train, 25)\n",
    "decision_tree_regression_test(np.array([1, 3.5, 6]), is_terminal, node_features, node_splits, node_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2207379865.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    # your implementation ends above\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# STEP 4\n",
    "# assuming that there are T terminal node\n",
    "# should print T rule sets as described\n",
    "def extract_rule_sets(is_terminal, node_features, node_splits, node_means):\n",
    "    # your implementation starts below\n",
    "    \n",
    "    # your implementation ends above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "37",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m P \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      2\u001b[0m is_terminal, node_features, node_splits, node_means \u001b[38;5;241m=\u001b[39m decision_tree_regression_train(X_train, y_train, P)\n\u001b[1;32m----> 3\u001b[0m y_interval_hat \u001b[38;5;241m=\u001b[39m \u001b[43mdecision_tree_regression_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_terminal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_means\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m fig \u001b[38;5;241m=\u001b[39m plot_figure(X_train, y_train, X_test, y_test, X_interval, y_interval_hat)\n\u001b[0;32m      5\u001b[0m fig\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecision_tree_regression_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(P), bbox_inches \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[82], line 8\u001b[0m, in \u001b[0;36mdecision_tree_regression_test\u001b[1;34m(X_query, is_terminal, node_features, node_splits, node_means)\u001b[0m\n\u001b[0;32m      6\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X_query\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X_query):\n\u001b[1;32m----> 8\u001b[0m     y_hat[i] \u001b[38;5;241m=\u001b[39m \u001b[43mdecision_tree_get_y_hat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_terminal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_means\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# your implementation ends above\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(y_hat)\n",
      "Cell \u001b[1;32mIn[81], line 3\u001b[0m, in \u001b[0;36mdecision_tree_get_y_hat\u001b[1;34m(x, is_terminal, node_features, node_splits, node_means)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecision_tree_get_y_hat\u001b[39m(x, is_terminal, node_features, node_splits, node_means):\n\u001b[0;32m      2\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_terminal\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m:  \u001b[38;5;66;03m# Continue until a terminal node is reached\u001b[39;00m\n\u001b[0;32m      5\u001b[0m         split \u001b[38;5;241m=\u001b[39m node_splits[node]\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m<\u001b[39m split:\n",
      "\u001b[1;31mKeyError\u001b[0m: 37"
     ]
    }
   ],
   "source": [
    "P = 20\n",
    "is_terminal, node_features, node_splits, node_means = decision_tree_regression_train(X_train, y_train, P)\n",
    "y_interval_hat = decision_tree_regression_test(X_interval, is_terminal, node_features, node_splits, node_means)\n",
    "fig = plot_figure(X_train, y_train, X_test, y_test, X_interval, y_interval_hat)\n",
    "fig.savefig(\"decision_tree_regression_{}.pdf\".format(P), bbox_inches = \"tight\")\n",
    "\n",
    "y_train_hat = decision_tree_regression_test(X_train, is_terminal, node_features, node_splits, node_means)\n",
    "rmse = np.sqrt(np.mean((y_train - y_train_hat)**2))\n",
    "print(\"RMSE on training set is {} when P is {}\".format(rmse, P))\n",
    "\n",
    "y_test_hat = decision_tree_regression_test(X_test, is_terminal, node_features, node_splits, node_means)\n",
    "rmse = np.sqrt(np.mean((y_test - y_test_hat)**2))\n",
    "print(\"RMSE on test set is {} when P is {}\".format(rmse, P))\n",
    "\n",
    "P = 50\n",
    "is_terminal, node_features, node_splits, node_means = decision_tree_regression_train(X_train, y_train, P)\n",
    "y_interval_hat = decision_tree_regression_test(X_interval, is_terminal, node_features, node_splits, node_means)\n",
    "fig = plot_figure(X_train, y_train, X_test, y_test, X_interval, y_interval_hat)\n",
    "fig.savefig(\"decision_tree_regression_{}.pdf\".format(P), bbox_inches = \"tight\")\n",
    "\n",
    "y_train_hat = decision_tree_regression_test(X_train, is_terminal, node_features, node_splits, node_means)\n",
    "rmse = np.sqrt(np.mean((y_train - y_train_hat)**2))\n",
    "print(\"RMSE on training set is {} when P is {}\".format(rmse, P))\n",
    "\n",
    "y_test_hat = decision_tree_regression_test(X_test, is_terminal, node_features, node_splits, node_means)\n",
    "rmse = np.sqrt(np.mean((y_test - y_test_hat)**2))\n",
    "print(\"RMSE on test set is {} when P is {}\".format(rmse, P))\n",
    "\n",
    "extract_rule_sets(is_terminal, node_features, node_splits, node_means)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
