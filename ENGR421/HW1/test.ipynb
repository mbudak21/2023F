{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"hw01_data_points.csv\", delimiter = \",\", dtype = str)\n",
    "y = np.genfromtxt(\"hw01_class_labels.csv\", delimiter = \",\", dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 21)\n",
      "(50000,)\n",
      "(44727, 21)\n",
      "(44727,)\n"
     ]
    }
   ],
   "source": [
    "# STEP 3\n",
    "# first 50000 data points should be included to train\n",
    "# remaining 44727 data points should be included to test\n",
    "# should return X_train, y_train, X_test, and y_test\n",
    "def train_test_split(X, y):\n",
    "    # your implementation starts below\n",
    "    trainset_size = 50000\n",
    "    X_train = X[:50000]\n",
    "    X_test = X[50000:]\n",
    "\n",
    "    y_train = y[:50000]\n",
    "    y_test = y[50000:]\n",
    "    # your implementation ends above\n",
    "    return(X_train, y_train, X_test, y_test)\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94727, 21)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(1, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04466, 0.95534]\n"
     ]
    }
   ],
   "source": [
    "# STEP 4\n",
    "# assuming that there are K classes\n",
    "# should return a numpy array with shape (K,)\n",
    "def estimate_prior_probabilities(y):\n",
    "    # your implementation starts below\n",
    "    \n",
    "    # Assume class numeration starts from 1\n",
    "    K = max(y) # Number of classes\n",
    "    size = y.shape[0] # Total size of set y\n",
    "    class_priors = []\n",
    "\n",
    "    for c in range(1, K): # From 1 to K-1\n",
    "        class_priors.append(sum(y==c)/size)\n",
    "\n",
    "    class_priors.append(1-sum(class_priors))\n",
    "    \n",
    "    # your implementation ends above\n",
    "    return(class_priors)\n",
    "\n",
    "class_priors = estimate_prior_probabilities(y_train)\n",
    "print(class_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| c: 1\n",
      "ic| c: 2\n"
     ]
    }
   ],
   "source": [
    "# STEP 5\n",
    "# assuming that there are K classes and D features\n",
    "# should return four numpy arrays with shape (K, D)\n",
    "def estimate_nucleotide_probabilities(X, y):\n",
    "    K = max(y)  # Number of classes (assuming y starts from 0)\n",
    "    D = X.shape[1]  # Number of features\n",
    "    \n",
    "    pAcd = np.zeros((K, D))\n",
    "    pCcd = np.zeros((K, D))\n",
    "    pGcd = np.zeros((K, D))\n",
    "    pTcd = np.zeros((K, D))\n",
    "    \n",
    "    for c in range(1, K+1):\n",
    "        # Filter data by class\n",
    "        X_c = X[y == c]\n",
    "        ic(c)\n",
    "        \n",
    "        for d in range(D):\n",
    "            feature_column = X_c[:, d]\n",
    "            total_samples = len(feature_column)\n",
    "            \n",
    "            pAcd[c-1][d] = np.sum(feature_column == 'A') / total_samples\n",
    "            pCcd[c-1][d] = np.sum(feature_column == 'C') / total_samples\n",
    "            pGcd[c-1][d] = np.sum(feature_column == 'G') / total_samples\n",
    "            pTcd[c-1][d] = np.sum(feature_column == 'T') / total_samples\n",
    "\n",
    "\n",
    "         \n",
    "    return pAcd, pCcd, pGcd, pTcd\n",
    "\n",
    "pAcd, pCcd, pGcd, pTcd = estimate_nucleotide_probabilities(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18674429 0.17913121 0.1437528  0.13390058 0.11912226 0.11374832\n",
      "  0.10523959 0.10076131 0.08687864 0.07613077 0.06941335 0.08687864\n",
      "  0.10120914 0.09628303 0.08105687 0.07926556 0.23510972 0.05015674\n",
      "  0.24540976 0.23734886 0.2539185 ]\n",
      " [0.26832332 0.27719974 0.2723219  0.25808613 0.28153328 0.27784872\n",
      "  0.27219629 0.26087048 0.25488308 0.26618795 0.27385015 0.26955848\n",
      "  0.28913266 0.28486193 0.27694852 0.25260117 0.27766031 0.24981682\n",
      "  0.28335462 0.28025624 0.29279628]]\n",
      "[[0.28616211 0.28526646 0.28571429 0.29422302 0.31168831 0.31751008\n",
      "  0.31034483 0.31258397 0.29735781 0.28034035 0.30541872 0.31840573\n",
      "  0.33811017 0.36945813 0.38916256 0.33990148 0.2955665  0.67845947\n",
      "  0.14464845 0.21988356 0.2539185 ]\n",
      " [0.22821195 0.22961459 0.22318756 0.22536479 0.21688613 0.22747922\n",
      "  0.22278979 0.22431804 0.24516926 0.22618125 0.20903553 0.21158959\n",
      "  0.20369711 0.20145707 0.22607658 0.24527393 0.21198736 0.32248205\n",
      "  0.22067536 0.24414345 0.210815  ]]\n",
      "[[0.15718764 0.15002239 0.1518137  0.14285714 0.14420063 0.13166144\n",
      "  0.12628751 0.11912226 0.09180475 0.10120914 0.11150918 0.11733094\n",
      "  0.11330049 0.08687864 0.06180027 0.06180027 0.21361397 0.00134348\n",
      "  0.50022391 0.18898343 0.2221227 ]\n",
      " [0.23763268 0.23371784 0.2370465  0.23957963 0.24077292 0.24613227\n",
      "  0.24098227 0.24696967 0.23233613 0.24558796 0.25802332 0.26143572\n",
      "  0.25800239 0.2659158  0.24190341 0.24449934 0.26585299 0.26924446\n",
      "  0.28672514 0.23241987 0.24140097]]\n",
      "[[0.36990596 0.38557994 0.41871921 0.42901926 0.4249888  0.43708016\n",
      "  0.45812808 0.46753247 0.5239588  0.54231975 0.51365876 0.47738468\n",
      "  0.44738021 0.44738021 0.4679803  0.51903269 0.25570981 0.2700403\n",
      "  0.10971787 0.35378415 0.2700403 ]\n",
      " [0.26583206 0.25946783 0.26744405 0.27696946 0.26080767 0.24853979\n",
      "  0.26403165 0.26784182 0.26761153 0.26204283 0.259091   0.25741621\n",
      "  0.24916784 0.24776519 0.25507149 0.25762556 0.24449934 0.15845668\n",
      "  0.20924488 0.24318044 0.25498775]]\n"
     ]
    }
   ],
   "source": [
    "print(pAcd)\n",
    "print(pCcd)\n",
    "print(pGcd)\n",
    "print(pTcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-32.29602984 -28.67631805]\n",
      " [-35.36510932 -29.06687849]\n",
      " [-33.1594779  -28.50829296]\n",
      " ...\n",
      " [-37.17901126 -29.28659414]\n",
      " [-35.6365549  -29.75138901]\n",
      " [-28.72885394 -28.68471489]]\n",
      "[[-31.88852108 -28.73182527]\n",
      " [-40.83809258 -29.40573888]\n",
      " [-30.6177392  -29.98270774]\n",
      " ...\n",
      " [-38.49757139 -28.9923932 ]\n",
      " [-24.40343148 -29.115305  ]\n",
      " [-37.58089652 -28.27846954]]\n"
     ]
    }
   ],
   "source": [
    "# STEP 6\n",
    "# assuming that there are N data points and K classes\n",
    "# should return a numpy array with shape (N, K)\n",
    "def calculate_score_values(X, pAcd, pCcd, pGcd, pTcd, class_priors):\n",
    "    # your implementation starts below\n",
    "    K = max(y)  # Number of classes (assuming y starts from 0)\n",
    "    N, D = X.shape  # Number of data entries, number of features\n",
    "\n",
    "    # Init score with priors\n",
    "    score_values = [np.log(x) for x in class_priors]\n",
    "    score_values = np.tile(np.log(class_priors), (N, 1))\n",
    "\n",
    "    #\n",
    "    pXcd = {\"A\":pAcd, \"C\":pCcd, \"G\":pGcd, \"T\":pTcd}\n",
    "\n",
    "    # # Add feature Likelihoods\n",
    "    # for i, row in X:\n",
    "    #     for d in row:\n",
    "    #         np.log(pXcd[d][i])\n",
    "\n",
    "    # Loop through each data point\n",
    "    for i in range(N):\n",
    "        # Loop through each class\n",
    "        for j in range(K):\n",
    "            # Loop through each feature (nucleotide in the sequence)\n",
    "            for d in range(D):\n",
    "                nucleotide = X[i][d]\n",
    "                score_values[i, j] += np.log(pXcd[nucleotide][j, d])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # your implementation ends above\n",
    "    return(score_values)\n",
    "\n",
    "scores_train = calculate_score_values(X_train, pAcd, pCcd, pGcd, pTcd, class_priors)\n",
    "print(scores_train)\n",
    "\n",
    "scores_test = calculate_score_values(X_test, pAcd, pCcd, pGcd, pTcd, class_priors)\n",
    "print(scores_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1489.  1460.]\n",
      " [  744. 46307.]]\n",
      "[[ 1314.  1300.]\n",
      " [  686. 41427.]]\n"
     ]
    }
   ],
   "source": [
    "# STEP 7\n",
    "# assuming that there are K classes\n",
    "# should return a numpy array with shape (K, K)\n",
    "def calculate_confusion_matrix(y_truth, scores):\n",
    "    # your implementation starts below\n",
    "    K = scores.shape[1]  # Number of classes\n",
    "    N = len(y_truth)  # Number of data points\n",
    "    \n",
    "    # Initialize confusion matrix with zeros\n",
    "    confusion_matrix = np.zeros((K, K))\n",
    "    \n",
    "    # Find the predicted class labels\n",
    "    predicted_classes = np.argmax(scores, axis=1)\n",
    "    \n",
    "    # Populate the confusion matrix\n",
    "    for n in range(N):\n",
    "        true_class = y_truth[n]\n",
    "        predicted_class = predicted_classes[n]\n",
    "        confusion_matrix[true_class-1][predicted_class] += 1\n",
    "    # your implementation ends above\n",
    "    return(confusion_matrix.T)\n",
    "\n",
    "confusion_train = calculate_confusion_matrix(y_train, scores_train)\n",
    "print(confusion_train)\n",
    "\n",
    "confusion_test = calculate_confusion_matrix(y_test, scores_test)\n",
    "print(confusion_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
